# Task ID: 7
# Title: Implement Font Detection Endpoint
# Status: done
# Dependencies: 2, 4
# Priority: medium
# Description: Create the /extract-fonts endpoint to detect and identify font family, size, and weight in design images.
# Details:
1. Create a font detection service in `/app/services/font_detector.py`:
```python
import cv2
import numpy as np
import pytesseract
from PIL import Image, ImageFont, ImageDraw
import io
import os

class FontDetector:
    # Define common fonts to compare against
    COMMON_FONTS = [
        "Arial", "Helvetica", "Roboto", "Open Sans", "Lato", 
        "Montserrat", "Times New Roman", "Georgia", "Courier New",
        "Verdana", "Tahoma", "Trebuchet MS", "Impact"
    ]
    
    @staticmethod
    def preprocess_image(image):
        """Preprocess image for text detection"""
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Apply thresholding
        _, binary = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        return binary
    
    @staticmethod
    def detect_text_regions(image):
        """Detect regions containing text"""
        # Preprocess the image
        binary = FontDetector.preprocess_image(image)
        
        # Find contours
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Filter contours to find potential text regions
        text_regions = []
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            # Filter based on aspect ratio and size
            aspect_ratio = w / float(h)
            if 0.1 < aspect_ratio < 15 and h > 8:  # Text-like aspect ratio and minimum height
                text_regions.append((x, y, w, h))
        
        return text_regions
    
    @staticmethod
    def estimate_font_size(region_height):
        """Estimate font size based on region height"""
        # Heuristic: font size is approximately 70-80% of the region height
        estimated_size = int(region_height * 0.75)
        
        # Round to common font sizes
        common_sizes = [8, 10, 12, 14, 16, 18, 20, 24, 28, 32, 36, 42, 48, 72]
        closest_size = min(common_sizes, key=lambda x: abs(x - estimated_size))
        
        return f"{closest_size}px"
    
    @staticmethod
    def estimate_font_weight(image, region):
        """Estimate font weight based on stroke thickness"""
        x, y, w, h = region
        roi = image[y:y+h, x:x+w]
        
        # Convert to binary if not already
        if len(roi.shape) > 2:
            roi = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
            _, roi = cv2.threshold(roi, 150, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # Calculate stroke width using distance transform
        dist = cv2.distanceTransform(roi, cv2.DIST_L2, 3)
        
        # Get average stroke width (non-zero values only)
        stroke_pixels = dist[dist > 0]
        if len(stroke_pixels) == 0:
            return "400"  # Default to normal weight
        
        avg_stroke = np.mean(stroke_pixels) * 2  # Multiply by 2 to get diameter
        
        # Map stroke width to font weight
        # This is a heuristic approach and may need calibration
        if avg_stroke < 1.5:
            return "300"  # Light
        elif avg_stroke < 2.5:
            return "400"  # Regular/Normal
        elif avg_stroke < 3.5:
            return "500"  # Medium
        elif avg_stroke < 4.5:
            return "600"  # Semi-bold
        else:
            return "700"  # Bold
    
    @staticmethod
    def detect_font(image):
        """Detect font properties in the image"""
        # Get text regions
        text_regions = FontDetector.detect_text_regions(image)
        
        if not text_regions:
            # Default values if no text regions found
            return {
                "family": "Unknown",
                "size": "16px",
                "weight": "400"
            }
        
        # Sort regions by area (largest first)
        text_regions.sort(key=lambda r: r[2] * r[3], reverse=True)
        
        # Use the largest text region for font analysis
        main_region = text_regions[0]
        
        # Estimate font size from region height
        font_size = FontDetector.estimate_font_size(main_region[3])
        
        # Estimate font weight
        font_weight = FontDetector.estimate_font_weight(image, main_region)
        
        # For font family, we'll use a simple heuristic approach
        # In a production system, this would be replaced with a more sophisticated
        # machine learning model trained on font samples
        font_family = "Roboto"  # Default to a common sans-serif font
        
        return {
            "family": font_family,
            "size": font_size,
            "weight": font_weight
        }
```

2. Create the font detection router in `/app/routers/fonts.py`:
```python
from fastapi import APIRouter, UploadFile, File, HTTPException
from ..services.image_processor import ImageProcessor
from ..services.font_detector import FontDetector
from ..utils.image_validator import validate_image

router = APIRouter()

@router.post("/extract-fonts")
async def extract_fonts(file: UploadFile = File(...)):
    try:
        # Validate and load image
        image_bytes = await validate_image(file)
        cv_image = ImageProcessor.load_cv2_image(image_bytes)
        
        # Detect fonts
        font_data = FontDetector.detect_font(cv_image)
        
        return font_data
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error detecting fonts: {str(e)}")
```

3. Update the main.py file to include the new router:
```python
from fastapi import FastAPI
from app.routers import colors, text, shapes, shadows, fonts

app = FastAPI(
    title="Low-Level Feature Extraction API",
    description="API for extracting design elements from images",
    version="1.0.0"
)

app.include_router(colors.router, tags=["colors"])
app.include_router(text.router, tags=["text"])
app.include_router(shapes.router, tags=["shapes"])
app.include_router(shadows.router, tags=["shadows"])
app.include_router(fonts.router, tags=["fonts"])
```

# Test Strategy:
1. Test with images containing text in various known fonts
2. Test with images containing text of different sizes
3. Test with images containing text with different weights (light, regular, bold)
4. Test with images containing multiple text styles
5. Test with images containing text on different backgrounds
6. Verify accuracy of font size estimation by comparing with known values
7. Verify accuracy of font weight detection
8. Test with images containing no text
9. Test performance with complex images to ensure response time is under 1 second
10. Test with different languages and character sets

# Subtasks:
## 1. Implement Font Detection Service [done]
### Dependencies: None
### Description: Create the core font detection logic in font_detector.py
### Details:
- Implement image preprocessing methods
- Create text region detection algorithm
- Develop font size and weight estimation logic
- Implement font family identification

## 2. Create Font Detection Endpoint [done]
### Dependencies: None
### Description: Develop the FastAPI endpoint for font detection
### Details:
- Implement /extract-fonts router
- Add input validation
- Integrate font detection service
- Handle error cases
- Ensure proper response formatting

## 3. Comprehensive Font Detection Testing [done]
### Dependencies: None
### Description: Create a comprehensive test suite for font detection
### Details:
- Develop unit tests for font detection service
- Create integration tests for /extract-fonts endpoint
- Test with various font styles, sizes, and backgrounds
- Verify performance and accuracy
- Test edge cases (no text, multiple text styles)

## 4. Update Project Documentation [done]
### Dependencies: None
### Description: Document the font detection feature and update project docs
### Details:
- Update API documentation
- Add examples of font detection usage
- Document limitations and expected accuracy
- Update README with new endpoint details
- Prepare usage guidelines

