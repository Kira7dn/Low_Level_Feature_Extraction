# Task ID: 6
# Title: Implement Shadow Analysis Endpoint
# Status: done
# Dependencies: 2
# Priority: medium
# Description: Create the /extract-shadows endpoint to detect shadow intensity in design images.
# Details:
1. Create a shadow analysis service in `/app/services/shadow_analyzer.py`:
```python
import cv2
import numpy as np

class ShadowAnalyzer:
    @staticmethod
    def preprocess_image(image):
        """Preprocess image for shadow detection"""
        # Convert to grayscale
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        
        # Apply Gaussian blur to reduce noise
        blurred = cv2.GaussianBlur(gray, (5, 5), 0)
        
        return blurred
    
    @staticmethod
    def detect_shadows(image):
        """Detect shadows in the image"""
        # Preprocess the image
        processed = ShadowAnalyzer.preprocess_image(image)
        
        # Apply adaptive thresholding to identify potential shadow regions
        thresh = cv2.adaptiveThreshold(
            processed, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
            cv2.THRESH_BINARY_INV, 11, 2
        )
        
        # Find contours in the thresholded image
        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # If no contours found, return default values
        if not contours:
            return {
                "shadow_level": "Low"
            }
        
        # Analyze shadow properties
        shadow_level = ShadowAnalyzer.analyze_intensity(processed, thresh)
        
        return {
            "shadow_level": shadow_level
        }
    
    @staticmethod
    def analyze_intensity(gray_img, thresh_img):
        """Analyze shadow intensity"""
        # Calculate the average darkness of shadow regions
        shadow_mask = thresh_img > 0
        if np.sum(shadow_mask) == 0:  # No shadow regions
            return "Low"
        
        shadow_pixels = gray_img[shadow_mask]
        avg_darkness = 255 - np.mean(shadow_pixels)
        
        # Categorize intensity based on average darkness
        if avg_darkness < 30:
            return "Low"
        elif avg_darkness < 60:
            return "Moderate"
        else:
            return "High"
```

2. Create the shadow analysis router in `/app/routers/shadows.py`:
```python
from fastapi import APIRouter, UploadFile, File, HTTPException
from ..services.image_processor import ImageProcessor
from ..services.shadow_analyzer import ShadowAnalyzer
from ..utils.image_validator import validate_image

router = APIRouter()

@router.post("/extract-shadows")
async def extract_shadows(file: UploadFile = File(...)):
    try:
        # Validate and load image
        image_bytes = await validate_image(file)
        cv_image = ImageProcessor.load_cv2_image(image_bytes)
        
        # Analyze shadows
        shadow_data = ShadowAnalyzer.detect_shadows(cv_image)
        
        return shadow_data
    except HTTPException as e:
        raise e
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error analyzing shadows: {str(e)}")
```

3. Update the main.py file to include the new router:
```python
from fastapi import FastAPI
from app.routers import colors, text, shapes, shadows

app = FastAPI(
    title="Low-Level Feature Extraction API",
    description="API for extracting design elements from images",
    version="1.0.0"
)

app.include_router(colors.router, tags=["colors"])
app.include_router(text.router, tags=["text"])
app.include_router(shapes.router, tags=["shapes"])
app.include_router(shadows.router, tags=["shadows"])
```

# Test Strategy:
1. Test with images containing UI elements with known shadow properties
2. Test with images containing subtle shadows
3. Test with images containing strong shadows
4. Test with images containing multiple shadows
5. Test with images containing no shadows
6. Verify accuracy of shadow intensity detection (Low/Moderate/High)
7. Test performance with complex images to ensure response time is under 1 second

# Subtasks:
## 1. Implement Image Preprocessing for Shadow Detection [done]
### Dependencies: None
### Description: Develop robust preprocessing steps to prepare input images for shadow analysis, including grayscale conversion and noise reduction.
### Details:
Use OpenCV to convert images to grayscale and apply Gaussian blur to minimize noise, ensuring consistent input for subsequent shadow detection algorithms.
<info added on 2025-05-12T13:04:02.112Z>
Implementation details for shadow_analyzer.py preprocessing module:

1. Image conversion pipeline:
   - Grayscale conversion implemented using cv2.cvtColor() with COLOR_BGR2GRAY flag
   - Gaussian blur applied with 5x5 kernel size for optimal noise reduction
   - Processing handles both color and grayscale input formats

2. Technical considerations:
   - OpenCV library utilized for efficient image processing operations
   - 5x5 kernel size provides balanced noise reduction while preserving important edge details
   - Grayscale conversion ensures consistent input for shadow detection algorithms
   - Implementation is generic and can process various image types and dimensions

3. Integration notes:
   - Preprocessing module designed to feed directly into the shadow detection algorithm
   - Method returns processed image ready for feature extraction and analysis
</info added on 2025-05-12T13:04:02.112Z>

## 2. Develop Shadow Detection Algorithm [done]
### Dependencies: 6.1
### Description: Create an algorithm to accurately identify shadow regions within preprocessed images.
### Details:
Apply adaptive thresholding to segment potential shadow regions, followed by contour detection to isolate shadow areas. Consider integrating region-based or learned-feature approaches for improved accuracy if needed[2][3][5].
<info added on 2025-05-12T13:04:43.264Z>
The shadow detection algorithm in shadow_analyzer.py leverages adaptive thresholding via cv2.adaptiveThreshold() in THRESH_BINARY_INV mode to robustly segment darker regions, which are likely to be shadows, even under varying lighting conditions. Gaussian adaptive thresholding is applied to enhance segmentation accuracy and minimize false positives. Contour detection using cv2.findContours() isolates and labels shadow regions, enabling precise identification and subsequent analysis. The algorithm includes a fallback mechanism to handle images with no detectable shadows, ensuring graceful degradation. This approach is optimized for design image contexts and is robust across different image types and shadow characteristics. The resulting shadow masks are prepared for downstream intensity and direction analysis, supporting the broader shadow analysis endpoint. Consideration is given to integrating region-based or learned-feature approaches for further accuracy improvements if required[2][3][5].
</info added on 2025-05-12T13:04:43.264Z>

## 3. Calculate Shadow Intensity [done]
### Dependencies: 6.2
### Description: Implement logic to quantify the darkness of detected shadow regions and categorize their intensity as High, Moderate, or Low.
### Details:
Analyze the average pixel intensity within shadow masks and classify the result as 'Low', 'Moderate', or 'High' based on calibrated thresholds. Use the following logic:
- If avg_darkness < 30: return "Low"
- If avg_darkness < 60: return "Moderate"
- Otherwise: return "High"

## 6. Integrate Endpoint and Perform Comprehensive Testing [done]
### Dependencies: 6.3
### Description: Integrate the shadow analysis logic into the /extract-shadows API endpoint and conduct end-to-end testing.
### Details:
Wire up the shadow analysis service to the FastAPI endpoint, ensuring correct image validation, error handling, and response formatting. The endpoint should return a simple JSON response with the shadow_level field (High/Moderate/Low). Perform comprehensive tests with diverse images to validate the full pipeline.

## 7. Update API Documentation [done]
### Dependencies: 6.6
### Description: Update API documentation to reflect the simplified shadow analysis endpoint that only returns shadow_level.
### Details:
Update the API documentation to clearly indicate that the /extract-shadows endpoint returns only the shadow_level field with possible values of 'High', 'Moderate', or 'Low'. Remove any references to shadow spread or direction from the documentation.

